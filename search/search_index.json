{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Neuro-CEILing","text":"<p>This project ...</p>"},{"location":"#dependencies","title":"Dependencies:","text":"<p>All the dependencies are in the environment.yml file. In order to have them installed, all you need is to have the following installed</p> <ul> <li>Python</li> <li>Conda</li> </ul> <p>To see how to set up the environment, see the set up environment page</p>"},{"location":"api/","title":"API","text":""},{"location":"api/#neuroceiling.configuration.DataStreamConfig","title":"<code>DataStreamConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>neuroceiling/configuration.py</code> <pre><code>class DataStreamConfig(BaseConfig):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, filename: str):\n        super().__init__(filename)\n        self.datastream_config: DataStreamBaseConfig = DataStreamBaseConfig(\"\")\n</code></pre>"},{"location":"api/#neuroceiling.configuration.DatasetConfig","title":"<code>DatasetConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>neuroceiling/configuration.py</code> <pre><code>class DatasetConfig(BaseConfig):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, filename: str):\n        super().__init__(filename)\n        self.dataset_config: DatasetBaseConfig = DatasetBaseConfig(\"\")\n</code></pre>"},{"location":"api/#neuroceiling.configuration.NeuroCeilingConfig","title":"<code>NeuroCeilingConfig</code>","text":"<p>               Bases: <code>BaseConfig</code></p> Source code in <code>neuroceiling/configuration.py</code> <pre><code>class NeuroCeilingConfig(BaseConfig):\n    \"\"\"\n\n    \"\"\"\n\n    def __init__(self, filename: str):\n        super().__init__(filename)\n</code></pre>"},{"location":"api/#neuroceiling.dataaquisition.dataset.DatasetBaseConfig","title":"<code>DatasetBaseConfig</code>","text":"<p>Base configuration class for every dataset.</p> <p>The configuration class tells the software which dataset is expected to be loaded.</p> <p>Every dataset configuration inherits from this class, and they extend it with the necessary information to make to be able to create its respective \"implementation\" object that inhertis from IDataset.</p> <p>Attributes: __DATASET_TYPE: Constant that determines the dataset type. It must be given in the constructor by its child class. subject_ids: Specifies a list of subject(s) to be fetched. If None, data of all subjects is fetched.</p> Source code in <code>neuroceiling/dataaquisition/dataset.py</code> <pre><code>class DatasetBaseConfig:\n    \"\"\"\n    Base configuration class for every dataset.\n\n    The configuration class tells the software which dataset is expected to be loaded.\n\n    Every dataset configuration inherits from this class, and they extend it with the necessary\n    information to make to be able to create its respective \"implementation\" object that inhertis from\n    IDataset.\n\n    Attributes: __DATASET_TYPE: Constant that determines the dataset type. It must be given in the constructor by its\n    child class.\n    subject_ids: Specifies a list of subject(s) to be fetched. If None, data of all subjects is fetched.\n    \"\"\"\n\n    def __init__(self, dataset_type: str):\n        \"\"\"\n        Constructor.\n\n        Parameters:\n            dataset_type: Dataset type, meant to be written by child class\n        \"\"\"\n        self.__DATASET_TYPE: str = dataset_type\n        self.subject_ids: list[int] = []\n\n    @property\n    def DATASET_TYPE(self) -&gt; str:\n        return self.__DATASET_TYPE\n</code></pre>"},{"location":"api/#neuroceiling.dataaquisition.dataset.DatasetBaseConfig.__init__","title":"<code>__init__(dataset_type)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> <ul> <li> <code>dataset_type</code>               (<code>str</code>)           \u2013            <p>Dataset type, meant to be written by child class</p> </li> </ul> Source code in <code>neuroceiling/dataaquisition/dataset.py</code> <pre><code>def __init__(self, dataset_type: str):\n    \"\"\"\n    Constructor.\n\n    Parameters:\n        dataset_type: Dataset type, meant to be written by child class\n    \"\"\"\n    self.__DATASET_TYPE: str = dataset_type\n    self.subject_ids: list[int] = []\n</code></pre>"},{"location":"api/#neuroceiling.dataaquisition.dataset.DatasetFactory","title":"<code>DatasetFactory</code>","text":"<p>Class that is responsible for creating the Dataset objects.</p> Source code in <code>neuroceiling/dataaquisition/dataset.py</code> <pre><code>class DatasetFactory:\n    \"\"\"\n    Class that is responsible for creating the Dataset objects.\n    \"\"\"\n\n    @classmethod\n    def get_dataset(cls, config: DatasetBaseConfig) -&gt; IDataset:\n        \"\"\"\n        Static method meant to create an instance of the dataset based on its configuration.\n\n        :param config: Configuration of dataset to be created\n        :return: The dataset instance\n        \"\"\"\n        module = __import__(\"neuroceiling.dataaquisition.\" + str.lower(config.DATASET_TYPE))\n        class_ = getattr(getattr(getattr(module, \"dataaquisition\"), str.lower(config.DATASET_TYPE)),\n                         config.DATASET_TYPE)\n        return class_(config)\n</code></pre>"},{"location":"api/#neuroceiling.dataaquisition.dataset.DatasetFactory.get_dataset","title":"<code>get_dataset(config)</code>  <code>classmethod</code>","text":"<p>Static method meant to create an instance of the dataset based on its configuration.</p> <p>:param config: Configuration of dataset to be created :return: The dataset instance</p> Source code in <code>neuroceiling/dataaquisition/dataset.py</code> <pre><code>@classmethod\ndef get_dataset(cls, config: DatasetBaseConfig) -&gt; IDataset:\n    \"\"\"\n    Static method meant to create an instance of the dataset based on its configuration.\n\n    :param config: Configuration of dataset to be created\n    :return: The dataset instance\n    \"\"\"\n    module = __import__(\"neuroceiling.dataaquisition.\" + str.lower(config.DATASET_TYPE))\n    class_ = getattr(getattr(getattr(module, \"dataaquisition\"), str.lower(config.DATASET_TYPE)),\n                     config.DATASET_TYPE)\n    return class_(config)\n</code></pre>"},{"location":"api/#neuroceiling.dataaquisition.dataset.IDataset","title":"<code>IDataset</code>","text":"<p>Interface class of a dataset.</p> <p>A dataset is a static, labeled bundle of data in which is used to train the brain decoding neural network.</p> <p>Every dataset implements this interface</p> Source code in <code>neuroceiling/dataaquisition/dataset.py</code> <pre><code>class IDataset(metaclass=abc.ABCMeta):\n    \"\"\" Interface class of a dataset.\n\n        A dataset is a static, labeled bundle of data in which is used to train the brain decoding neural network.\n\n        Every dataset implements this interface\n    \"\"\"\n\n    def __init__(self, config: DatasetBaseConfig):\n        self.__TYPE_NAME: str = config.DATASET_TYPE\n        self.__subject_ids: type(config.subject_ids) = config.subject_ids\n        self._raw_dataset: Optional[braindecode.datasets.BaseConcatDataset] = None\n\n    @abc.abstractmethod\n    def load_dataset(self) -&gt; None:\n        pass\n\n    @property\n    def TYPE_NAME(self) -&gt; str:\n        return self.__TYPE_NAME\n\n    @property\n    def subject_ids(self) -&gt; list[int]:\n        return self.__subject_ids\n\n    @property\n    def raw_dataset(self) -&gt; Optional[braindecode.datasets.BaseConcatDataset]:\n        return self._raw_dataset\n</code></pre>"},{"location":"environment/","title":"Setup/Update Environment","text":""},{"location":"environment/#setup-conda-environment","title":"Setup Conda environment","text":"<p>To set up the environment, one can simply create a conda environment based on the YAML file and activate it by running</p> <pre><code>conda env create -f environment.yml\nconda activate neuro-ceiling\n</code></pre>"},{"location":"environment/#update-yaml-file-from-environment","title":"Update YAML file from environment","text":"<pre><code>conda env export -f environment.yml --no-builds\n</code></pre>"},{"location":"environment/#update-the-environment-from-yaml-file","title":"Update the environment from YAML file","text":"<pre><code>conda env update --name neuro-ceiling --file environment.yml  --prune\n</code></pre>"},{"location":"environment/#setup-maniskill2-env","title":"Setup ManiSkill2 env","text":"<p>Download an example ReplicaCAD scene from Habitat <pre><code>wget https://dl.fbaipublicfiles.com/habitat/ReplicaCAD/hab2_bench_assets.zip -P data\ncd data &amp;&amp; unzip -q hab2_bench_assets.zip -d hab2_bench_assets\n</code></pre></p>"},{"location":"environment/#remote-development-x11-forwarding","title":"Remote Development X11 Forwarding","text":"<p>To use it make sure the ~/.ssh/config contains the following:</p> <pre><code>Host *\nForwardX11 yes\nForwardX11Trusted yes\n</code></pre>"},{"location":"notes/","title":"Notes","text":"<p>Workflow Load dataset or sample data from EEG</p>"},{"location":"notes/#notes","title":"Notes","text":"<p>We will use supervised learning to learn the EEG \u2192 Actions decoder. First, we will use publicly available and labeled datasets to train a NN.</p> <p>Afterward, we try to train a NN using our own datasets, sampled with the cap.</p> <p>The EEG will generate \"noisy\" action labels due to the noise in the EEG. The idea is to check if the CEILing framework can be used with these noisy labels.</p>"},{"location":"notes/#eeg","title":"EEG","text":""},{"location":"notes/#learning-nn","title":"Learning NN","text":"<p>We will first sample and store labeled datasets and have offline supervised learning of an NN.</p> <p>There can be two sources of data:  - Braindecode public available datasets  - Our own sampled dataset using the EEG cap + gamepad</p> <p>-[ ] Do we need to push the EEG data to ROS?</p>"},{"location":"notes/#using-nn-to-decode-actions","title":"Using NN to decode actions","text":"<p>We want to get a \"live stream\" of data (EEG) sampling, \"decode\" and action, and then feed it to the Action-Motion policy from the CEILing.</p>"},{"location":"notes/#sampling-from-cap","title":"Sampling from \"Cap\"","text":"<ul> <li>PC password: neuro</li> <li>SW password: 0000</li> <li>Sampling rate: 1 kHz</li> <li>Amplifier: EEG64-CY-261</li> <li>Raw data.</li> </ul>"},{"location":"notes/#action-motion","title":"Action \u2192 Motion","text":"<p>The second step is to use the CEILing framework to train Actions to Motion. To perform the feedback we have:</p> <ul> <li>Action \u2192 Motion</li> <li>Evaluative feedback (human): ??</li> <li>Corrective feedback (human): ??</li> <li>Comparison feedback (human): ??</li> </ul>"},{"location":"notes/#questions","title":"QUESTIONS","text":"<ul> <li>How to get the event_codes from the dataset?</li> <li>Create custom dataset with my events?</li> <li>I am creating an MNE dataset from my dataset, so then I can create an annotated BrainDecode  dataset, but as far as I understand, I can only generate discrete events \"either 1 or -1\", not \"0.9\". Could this be a problem for the future, when we integrate the robot?</li> </ul>"},{"location":"design/design/","title":"Design","text":"<p>This page is meant to show the overview and design of the project</p> <p></p>"}]}